{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11fe7c2",
   "metadata": {
    "colab_type": "text",
    "id": "7yuytuIllsv1"
   },
   "source": [
    "\n",
    "# Transformer Summarizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3e7b6b",
   "metadata": {
    "colab_type": "text",
    "id": "H4NlfEQhRWPy"
   },
   "source": [
    "<a name='0'></a>\n",
    "## Introduction\n",
    "\n",
    "Summarization is an important task in natural language processing and could be useful for a consumer enterprise. For example, bots can be used to scrape articles, summarize them, and then you can use sentiment analysis to identify the sentiment about certain stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c22ab7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "CChWzW-rEHVb",
    "outputId": "a0b3e98b-7fc6-492d-c8ad-3a263b54f670",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import utils\n",
    "\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "tf.keras.utils.set_random_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c1984b",
   "metadata": {
    "colab_type": "text",
    "id": "kEL2rvaHRWP4"
   },
   "source": [
    "<a name='1'></a>\n",
    "## Importing the Dataset\n",
    "\n",
    "The `utils.py` file has all the necessary functions required to preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86382835",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:\n",
      "Lucas: Hey! How was your day?\r\n",
      "Demi: Hey there! \r\n",
      "Demi: It was pretty fine, actually, thank you!\r\n",
      "Demi: I just got promoted! :D\r\n",
      "Lucas: Whoa! Great news!\r\n",
      "Lucas: Congratulations!\r\n",
      "Lucas: Such a success has to be celebrated.\r\n",
      "Demi: I agree! :D\r\n",
      "Demi: Tonight at Death & Co.?\r\n",
      "Lucas: Sure!\r\n",
      "Lucas: See you there at 10pm?\r\n",
      "Demi: Yeah! See you there! :D\n",
      "\n",
      "Summary:\n",
      "Demi got promoted. She will celebrate that with Lucas at Death & Co at 10 pm.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/corpus\"\n",
    "\n",
    "train_data, test_data = utils.get_train_test_data(data_dir)\n",
    "\n",
    "# Take one example from the dataset and print it\n",
    "example_summary, example_dialogue = train_data.iloc[10]\n",
    "print(f\"Dialogue:\\n{example_dialogue}\")\n",
    "print(f\"\\nSummary:\\n{example_summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128c6da1",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## Preprocess the data\n",
    "\n",
    "First we will do some preprocessing of the data and split it into inputs and outputs. Here we will also remove some of the characters that are specific to this dataset and add the `[EOS]` (end of sentence) token to the end, will also add a `[SOS]` (start of sentence) token to the beginning of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5831d65",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "document, summary = utils.preprocess(train_data)\n",
    "document_test, summary_test = utils.preprocess(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff1d1d3",
   "metadata": {},
   "source": [
    "Now performing the standard preprocessing with the tensorflow library. We need to modify the filters, because we dont want the `[EOS]` tokens to be removed.\n",
    "\n",
    "Then creating the vocabulary by combining the data in the documents and the summaries and using `.fit_on_texts()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbed10b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 34250\n"
     ]
    }
   ],
   "source": [
    "# The [ and ] from default tokens cannot be removed, because they mark the SOS and EOS token.\n",
    "filters = '!\"#$%&()*+,-./:;<=>?@\\\\^_`{|}~\\t\\n'\n",
    "oov_token = '[UNK]'\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token, lower=False)\n",
    "\n",
    "documents_and_summary = pd.concat([document, summary], ignore_index=True)\n",
    "\n",
    "tokenizer.fit_on_texts(documents_and_summary)\n",
    "\n",
    "inputs = tokenizer.texts_to_sequences(document)\n",
    "targets = tokenizer.texts_to_sequences(summary)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(f'Size of vocabulary: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89628836",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Limit the size of the input and output data for being able to run it in this environment.\n",
    "encoder_maxlen = 150\n",
    "decoder_maxlen = 50\n",
    "\n",
    "# Pad the sequences.\n",
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')\n",
    "\n",
    "inputs = tf.cast(inputs, dtype=tf.int32)\n",
    "targets = tf.cast(targets, dtype=tf.int32)\n",
    "\n",
    "# Create the final training dataset.\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df416b",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## Positional Encoding\n",
    "\n",
    "In sequence to sequence tasks, the relative order of our data is extremely important to its meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44510776",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d_model):\n",
    "    \"\"\"\n",
    "    Precomputes a matrix with all the positional encodings \n",
    "    \n",
    "    Arguments:\n",
    "        positions (int): Maximum number of positions to be encoded \n",
    "        d_model (int): Encoding size \n",
    "    \n",
    "    Returns:\n",
    "        pos_encoding (tf.Tensor): A matrix of shape (1, position, d_model) with the positional encodings\n",
    "    \"\"\"\n",
    "    \n",
    "    position = np.arange(positions)[:, np.newaxis]\n",
    "    k = np.arange(d_model)[np.newaxis, :]\n",
    "    i = k // 2\n",
    "    \n",
    "    # initialize a matrix angle_rads of all the angles \n",
    "    angle_rates = 1 / np.power(10000, (2 * i) / np.float32(d_model))\n",
    "    angle_rads = position * angle_rates\n",
    "  \n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa2ab79",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## Masking\n",
    "\n",
    "There are two types of masks that are useful when building our Transformer network: the *padding mask* and the *look-ahead mask*. Both help the softmax computation give the appropriate weights to the words in our input sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5010bfa6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(decoder_token_ids):\n",
    "    \"\"\"\n",
    "    Creates a matrix mask for the padding cells\n",
    "    \n",
    "    Arguments:\n",
    "        decoder_token_ids (matrix like): matrix of size (n, m)\n",
    "    \n",
    "    Returns:\n",
    "        mask (tf.Tensor): binary tensor of size (n, 1, m)\n",
    "    \"\"\"    \n",
    "    seq = 1 - tf.cast(tf.math.equal(decoder_token_ids, 0), tf.float32)\n",
    "  \n",
    "    # add extra dimensions to add the padding to the attention logits. \n",
    "    # this will allow for broadcasting later when comparing sequences\n",
    "    return seq[:, tf.newaxis, :] \n",
    "\n",
    "\n",
    "def create_look_ahead_mask(sequence_length):\n",
    "    \"\"\"\n",
    "    Returns a lower triangular matrix filled with ones\n",
    "    \n",
    "    Arguments:\n",
    "        sequence_length (int): matrix size\n",
    "    \n",
    "    Returns:\n",
    "        mask (tf.Tensor): binary tensor of size (sequence_length, sequence_length)\n",
    "    \"\"\"\n",
    "    mask = tf.linalg.band_part(tf.ones((1, sequence_length, sequence_length)), -1, 0)\n",
    "    return mask "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad27d38",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Self-Attention\n",
    "\n",
    "As the authors of the Transformers paper state, \"Attention is All You Need\". \n",
    "\n",
    "<img src=\"images/self-attention.png\" alt=\"Encoder\" width=\"600\"/>\n",
    "<caption><center><font color='purple'><b>Figure 1: Self-Attention calculation visualization</font></center></caption>\n",
    "    \n",
    "The use of self-attention paired with traditional convolutional networks allows for parallelization which speeds up training. We  will implement **scaled dot product attention** which takes in a query, key, value, and a mask as inputs to return rich, attention-based vector representations of the words in your sequence. This type of self-attention can be mathematically expressed as:\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{4}\\\n",
    "$$\n",
    "\n",
    "* $Q$ is the matrix of queries \n",
    "* $K$ is the matrix of keys\n",
    "* $V$ is the matrix of values\n",
    "* $M$ is the optional mask you choose to apply \n",
    "* ${d_k}$ is the dimension of the keys, which is used to scale everything down so the softmax doesn't explode\n",
    "\n",
    "<a name='ex-1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39f8f820",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"\n",
    "    Calculate the attention weights.\n",
    "      q, k, v must have matching leading dimensions.\n",
    "      k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "      The mask has different shapes depending on its type(padding or look ahead) \n",
    "      but it must be broadcastable for addition.\n",
    "\n",
    "    Arguments:\n",
    "        q (tf.Tensor): query of shape (..., seq_len_q, depth)\n",
    "        k (tf.Tensor): key of shape (..., seq_len_k, depth)\n",
    "        v (tf.Tensor): value of shape (..., seq_len_v, depth_v)\n",
    "        mask (tf.Tensor): mask with shape broadcastable \n",
    "              to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        output -- attention_weights\n",
    "    \"\"\"\n",
    "    \n",
    "    # Multiply q and k transposed.\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    # scale matmul_qk with the square root of dk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:  # Don't replace this None\n",
    "        scaled_attention_logits += (1 - mask) * -1e9\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores add up to 1.\n",
    "    attention_weights = tf.keras.activations.softmax(scaled_attention_logits)\n",
    "\n",
    "    # Multiply the attention weights by v\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    \n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0e9dc69",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " [[[1.   0.62]\n",
      "  [0.62 0.62]\n",
      "  [0.74 0.31]]]\n",
      "\n",
      "Attention weigths:\n",
      " [[[0.   0.38 0.   0.23 0.38]\n",
      "  [0.38 0.   0.   0.23 0.38]\n",
      "  [0.26 0.43 0.   0.16 0.16]]]\n"
     ]
    }
   ],
   "source": [
    "# Test your function!\n",
    "q = np.array([[1, 1, 0, 1], [0, 1, 1, 1], [1, 0, 1, 1]]).astype(np.float32)\n",
    "k = np.array([[1, 1, 0, 1], [1, 0, 1, 1 ], [1, 1, 1, 0], [0, 0, 0, 1], [0, 1, 0, 1]]).astype(np.float32)\n",
    "v = np.array([[0, 0], [1, 0], [1, 0], [1, 1], [1, 1]]).astype(np.float32)\n",
    "mask = np.array([[[0, 1, 0, 1, 1], [1, 0, 0, 1, 1], [1, 1, 0, 1, 1]]])\n",
    "\n",
    "ou, atw = scaled_dot_product_attention(q, k, v, mask)\n",
    "ou = np.around(ou, decimals=2)\n",
    "atw = np.around(atw, decimals=2)\n",
    "\n",
    "print(f\"Output:\\n {ou}\")\n",
    "print(f\"\\nAttention weigths:\\n {atw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf299e73",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "##  Encoder\n",
    "\n",
    "The Transformer Encoder layer pairs self-attention and convolutional neural network style of processing to improve the speed of training and passes K and V matrices to the Decoder, which we'll build later.\n",
    "<img src=\"images/encoder_layer.png\" alt=\"Encoder\" width=\"400\"/>\n",
    "<caption><center><font color='purple'><b>Figure 2a: Transformer encoder layer</font></center></caption>\n",
    "\n",
    "* `MultiHeadAttention` you can think of as computing the self-attention several times to detect different features. \n",
    "* Feed forward neural network contains two Dense layers which we'll implement as the function `FullyConnected`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c96bf8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def FullyConnected(embedding_dim, fully_connected_dim):\n",
    "    \"\"\"\n",
    "    Returns a sequential model consisting of two dense layers. The first dense layer has\n",
    "    fully_connected_dim neurons and is activated by relu. The second dense layer has\n",
    "    embedding_dim and no activation.\n",
    "\n",
    "    Arguments:\n",
    "        embedding_dim (int): output dimension\n",
    "        fully_connected_dim (int): dimension of the hidden layer\n",
    "\n",
    "    Returns:\n",
    "        _ (tf.keras.Model): sequential model\n",
    "    \"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(fully_connected_dim, activation='relu'),  # (batch_size, seq_len, d_model)\n",
    "        tf.keras.layers.Dense(embedding_dim)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f21d9",
   "metadata": {},
   "source": [
    "<a name='6-1'></a>\n",
    "### Encoder Layer\n",
    "\n",
    "Now we will pair multi-head attention and feed forward neural network together in an encoder layer! We will also use residual connections and layer normalization to help speed up training (Figure 2a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1755590",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The encoder layer is composed by a multi-head self-attention mechanism,\n",
    "    followed by a simple, positionwise fully connected feed-forward network. \n",
    "    This architecture includes a residual connection around each of the two \n",
    "    sub-layers, followed by layer normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
    "                 dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        \n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.ffn = FullyConnected(\n",
    "            embedding_dim=embedding_dim,\n",
    "            fully_connected_dim=fully_connected_dim\n",
    "        )\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask (tf.Tensor): Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "        Returns:\n",
    "            encoder_layer_out (tf.Tensor): Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        # calculate self-attention using mha(~1 line).\n",
    "        # Dropout is added by Keras automatically if the dropout parameter is non-zero during training\n",
    "        self_mha_output = self.mha(x, x, x, mask)  # Self attention (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # skip connection\n",
    "        # apply layer normalization on sum of the input and the attention output to get the  \n",
    "        # output of the multi-head attention layer\n",
    "        skip_x_attention = self.layernorm1(x + self_mha_output)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "\n",
    "        # pass the output of the multi-head attention layer through a ffn\n",
    "        ffn_output = self.ffn(skip_x_attention)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # apply dropout layer to ffn output during training\n",
    "        # use `training=training`\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training)\n",
    "        \n",
    "        # apply layer normalization on sum of the output from multi-head attention (skip connection) and ffn output\n",
    "        # to get the output of the encoder layer\n",
    "        encoder_layer_out = self.layernorm2(skip_x_attention + ffn_output)  # (batch_size, input_seq_len, embedding_dim)\n",
    "        \n",
    "        return encoder_layer_out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc286e22",
   "metadata": {},
   "source": [
    "<a name='6-2'></a>\n",
    "### Full Encoder\n",
    "\n",
    "Now we're ready to build the full Transformer Encoder (Figure 2b), where we will embed our input and add the positional encodings that we calculated. We will then feed our encoded embeddings to a stack of Encoder layers. \n",
    "\n",
    "<img src=\"images/encoder.png\" alt=\"Encoder\" width=\"330\"/>\n",
    "<caption><center><font color='purple'><b>Figure 2b: Transformer Encoder</font></center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cae3bf52",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The entire Encoder starts by passing the input to an embedding layer \n",
    "    and using positional encoding to then pass the output through a stack of\n",
    "    encoder Layers\n",
    "        \n",
    "    \"\"\"  \n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size,\n",
    "               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.embedding_dim)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps) \n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder\n",
    "        \n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, seq_len, embedding_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask (tf.Tensor): Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "\n",
    "        Returns:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        # Pass input through the Embedding layer\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, embedding_dim)\n",
    "        # Scale embedding by multiplying it by the square root of the embedding dimension\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        # Add the position encoding to embedding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        # Pass the encoded embedding through a dropout layer\n",
    "        # use `training=training`\n",
    "        x = self.dropout(x, training=training)\n",
    "        # Pass the output through the stack of encoding layers \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06224c45",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## Decoder\n",
    "\n",
    "Now it is time to implement the decoder. The Decoder layer takes the K and V matrices generated by the Encoder and computes the second multi-head attention layer with the Q matrix from the output (Figure 3a).\n",
    "\n",
    "<img src=\"images/decoder_layer.png\" alt=\"Decoder\" width=\"250\"/>\n",
    "<caption><center><font color='purple'><b>Figure 3a: Transformer Decoder layer</font></center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e16f6201",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The decoder layer is composed by two multi-head attention blocks, \n",
    "    one that takes the new input and uses self-attention, and the other \n",
    "    one that combines it with the output of the encoder, followed by a\n",
    "    fully connected block. \n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.mha2 = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.ffn = FullyConnected(\n",
    "            embedding_dim=embedding_dim,\n",
    "            fully_connected_dim=fully_connected_dim\n",
    "        )\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Decoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            enc_output (tf.Tensor): Tensor of shape(batch_size, input_seq_len, fully_connected_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n",
    "            padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            out3 (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            attn_weights_block1 (tf.Tensor): Tensor of shape (batch_size, num_heads, target_seq_len, target_seq_len)\n",
    "            attn_weights_block2 (tf.Tensor): Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \"\"\"\n",
    "        \n",
    "        # enc_output.shape == (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # BLOCK 1\n",
    "        # calculate self-attention and return attention scores as attn_weights_block1.\n",
    "        # Dropout will be applied during training.\n",
    "        mult_attn_out1, attn_weights_block1 = self.mha1(x, x, return_attention_scores=True, attention_mask=look_ahead_mask)\n",
    "        \n",
    "        # apply layer normalization (layernorm1) to the sum of the attention output and the input\n",
    "        Q1 = self.layernorm1(x + mult_attn_out1)\n",
    "\n",
    "        # BLOCK 2\n",
    "        # calculate self-attention using the Q from the first block and K and V from the encoder output. \n",
    "        # Dropout will be applied during training\n",
    "        # Return attention scores as attn_weights_block2\n",
    "        mult_attn_out2, attn_weights_block2 = self.mha2(Q1, enc_output, return_attention_scores=True, \n",
    "                                                        attention_mask=padding_mask)\n",
    "        \n",
    "        # apply layer normalization (layernorm2) to the sum of the attention output and the output of the first block\n",
    "        mult_attn_out2 = self.layernorm2(Q1 + mult_attn_out2)\n",
    "                \n",
    "        #BLOCK 3\n",
    "        # pass the output of the second block through a ffn\n",
    "        ffn_output = self.ffn(mult_attn_out2)\n",
    "        \n",
    "        # apply a dropout layer to the ffn output\n",
    "        # use `training=training`\n",
    "        ffn_output = self.dropout_ffn(ffn_output, training=training)\n",
    "        \n",
    "        # apply layer normalization (layernorm3) to the sum of the ffn output and the output of the second block\n",
    "        out3 = self.layernorm3(mult_attn_out2 + ffn_output)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cff8596",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding_dim=12 and num_heads=16:\n",
      "\n",
      "q has shape:(1, 15, 12)\n",
      "Output of encoder has shape:(1, 7, 8)\n",
      "\n",
      "Output of decoder layer has shape:(1, 15, 12)\n",
      "Att Weights Block 1 has shape:(1, 16, 15, 15)\n",
      "Att Weights Block 2 has shape:(1, 16, 15, 7)\n"
     ]
    }
   ],
   "source": [
    "# Test your function!\n",
    "key_dim = 12\n",
    "n_heads = 16\n",
    "\n",
    "decoderLayer_test = DecoderLayer(embedding_dim=key_dim, num_heads=n_heads, fully_connected_dim=32)\n",
    "\n",
    "q = np.ones((1, 15, key_dim))\n",
    "encoder_test_output = tf.convert_to_tensor(np.random.rand(1, 7, 8))\n",
    "look_ahead_mask = create_look_ahead_mask(q.shape[1])\n",
    "\n",
    "out, attn_w_b1, attn_w_b2 = decoderLayer_test(q, encoder_test_output, False, look_ahead_mask, None)\n",
    "\n",
    "print(f\"Using embedding_dim={key_dim} and num_heads={n_heads}:\\n\")\n",
    "print(f\"q has shape:{q.shape}\")\n",
    "print(f\"Output of encoder has shape:{encoder_test_output.shape}\\n\")\n",
    "\n",
    "print(f\"Output of decoder layer has shape:{out.shape}\")\n",
    "print(f\"Att Weights Block 1 has shape:{attn_w_b1.shape}\")\n",
    "print(f\"Att Weights Block 2 has shape:{attn_w_b2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a94b3f",
   "metadata": {},
   "source": [
    "<a name='7-2'></a> \n",
    "### Full Decoder\n",
    "Time to use our Decoder layer to build a full Transformer Decoder (Figure 3b). We will now embed our output and add positional encodings. And then feed our encoded embeddings to a stack of Decoder layers. \n",
    "\n",
    "\n",
    "<img src=\"images/decoder.png\" alt=\"Decoder\" width=\"300\"/>\n",
    "<caption><center><font color='purple'><b>Figure 3b: Transformer Decoder</font></center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b42d7b92",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The entire Encoder starts by passing the target input to an embedding layer \n",
    "    and using positional encoding to then pass the output through a stack of\n",
    "    decoder Layers\n",
    "        \n",
    "    \"\"\" \n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, target_vocab_size,\n",
    "               maximum_position_encoding, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, self.embedding_dim)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.embedding_dim)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps) \n",
    "                           for _ in range(self.num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Forward  pass for the Decoder\n",
    "        \n",
    "        Arguments:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            enc_output (tf.Tensor):  Tensor of shape(batch_size, input_seq_len, fully_connected_dim)\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n",
    "            padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            x (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "            attention_weights (dict[str: tf.Tensor]): Dictionary of tensors containing all the attention weights\n",
    "                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        # create word embeddings \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # scale embeddings by multiplying by the square root of their dimension\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        \n",
    "        # add positional encodings to word embedding\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        # apply a dropout layer to x\n",
    "        # use `training=training`\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        # use a for loop to pass x through a stack of decoder layers and update attention_weights\n",
    "        for i in range(self.num_layers):\n",
    "            # pass x and the encoder output through a stack of decoder layers and save the attention weights\n",
    "            # of block 1 and 2 (~1 line)\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            #update attention_weights dictionary with the attention weights of block 1 and block 2\n",
    "            attention_weights['decoder_layer{}_block1_self_att'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2_decenc_att'.format(i+1)] = block2\n",
    "        \n",
    "        # x.shape == (batch_size, target_seq_len, fully_connected_dim)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ea66734",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using num_layers=5, embedding_dim=13 and num_heads=17:\n",
      "\n",
      "x has shape:(3, 4)\n",
      "Output of encoder has shape:(3, 7, 9)\n",
      "\n",
      "Output of decoder has shape:(3, 4, 13)\n",
      "\n",
      "Attention weights:\n",
      "decoder_layer1_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer1_block2_decenc_att has shape:(3, 17, 4, 7)\n",
      "decoder_layer2_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer2_block2_decenc_att has shape:(3, 17, 4, 7)\n",
      "decoder_layer3_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer3_block2_decenc_att has shape:(3, 17, 4, 7)\n",
      "decoder_layer4_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer4_block2_decenc_att has shape:(3, 17, 4, 7)\n",
      "decoder_layer5_block1_self_att has shape:(3, 17, 4, 4)\n",
      "decoder_layer5_block2_decenc_att has shape:(3, 17, 4, 7)\n"
     ]
    }
   ],
   "source": [
    "# Test your function!\n",
    "n_layers = 5\n",
    "emb_d = 13\n",
    "n_heads = 17\n",
    "fully_connected_dim = 16\n",
    "target_vocab_size = 300\n",
    "maximum_position_encoding = 6\n",
    "\n",
    "x = np.array([[3, 2, 1, 1], [2, 1, 1, 0], [2, 1, 1, 0]])\n",
    "\n",
    "encoder_test_output = tf.convert_to_tensor(np.random.rand(3, 7, 9))\n",
    "\n",
    "look_ahead_mask = create_look_ahead_mask(x.shape[1])\n",
    "\n",
    "decoder_test = Decoder(n_layers, emb_d, n_heads, fully_connected_dim, target_vocab_size,maximum_position_encoding)\n",
    "                   \n",
    "outd, att_weights = decoder_test(x, encoder_test_output, False, look_ahead_mask, None)\n",
    "\n",
    "print(f\"Using num_layers={n_layers}, embedding_dim={emb_d} and num_heads={n_heads}:\\n\")\n",
    "print(f\"x has shape:{x.shape}\")\n",
    "print(f\"Output of encoder has shape:{encoder_test_output.shape}\\n\")\n",
    "\n",
    "print(f\"Output of decoder has shape:{outd.shape}\\n\")\n",
    "print(\"Attention weights:\")\n",
    "for name, tensor in att_weights.items():\n",
    "    print(f\"{name} has shape:{tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c3044d",
   "metadata": {},
   "source": [
    "<a name='8'></a> \n",
    "## Transformer\n",
    "\n",
    "Now it's time to put it all together.  \n",
    "\n",
    "<img src=\"images/transformer.png\" alt=\"Transformer\" width=\"550\"/>\n",
    "<caption><center><font color='purple'><b>Figure 4: Transformer</font></center></caption>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "66b46af6",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Complete transformer with an Encoder and a Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, embedding_dim, num_heads, fully_connected_dim, input_vocab_size, \n",
    "               target_vocab_size, max_positional_encoding_input,\n",
    "               max_positional_encoding_target, dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers=num_layers,\n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               input_vocab_size=input_vocab_size,\n",
    "                               maximum_position_encoding=max_positional_encoding_input,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.decoder = Decoder(num_layers=num_layers, \n",
    "                               embedding_dim=embedding_dim,\n",
    "                               num_heads=num_heads,\n",
    "                               fully_connected_dim=fully_connected_dim,\n",
    "                               target_vocab_size=target_vocab_size, \n",
    "                               maximum_position_encoding=max_positional_encoding_target,\n",
    "                               dropout_rate=dropout_rate,\n",
    "                               layernorm_eps=layernorm_eps)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size, activation='softmax')\n",
    "    \n",
    "    def call(self, input_sentence, output_sentence, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the entire Transformer\n",
    "        Arguments:\n",
    "            input_sentence (tf.Tensor): Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "                              An array of the indexes of the words in the input sentence\n",
    "            output_sentence (tf.Tensor): Tensor of shape (batch_size, target_seq_len, fully_connected_dim)\n",
    "                              An array of the indexes of the words in the output sentence\n",
    "            training (bool): Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            enc_padding_mask (tf.Tensor): Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "            look_ahead_mask (tf.Tensor): Boolean mask for the target_input\n",
    "            dec_padding_mask (tf.Tensor): Boolean mask for the second multihead attention layer\n",
    "        Returns:\n",
    "            final_output (tf.Tensor): The final output of the model\n",
    "            attention_weights (dict[str: tf.Tensor]): Dictionary of tensors containing all the attention weights for the decoder\n",
    "                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)\n",
    "        \n",
    "        \"\"\"\n",
    "        # call self.encoder with the appropriate arguments to get the encoder output\n",
    "        enc_output = self.encoder(input_sentence, training, enc_padding_mask)\n",
    "        \n",
    "        # call self.decoder with the appropriate arguments to get the decoder output\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, fully_connected_dim)\n",
    "        dec_output, attention_weights = self.decoder(output_sentence, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "        \n",
    "        # pass decoder output through a linear layer and softmax\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f8b4eb8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using num_layers=3, target_vocab_size=350 and num_heads=17:\n",
      "\n",
      "sentence_a has shape:(1, 7)\n",
      "sentence_b has shape:(1, 7)\n",
      "\n",
      "Output of transformer (summary) has shape:(1, 7, 350)\n",
      "\n",
      "Attention weights:\n",
      "decoder_layer1_block1_self_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer1_block2_decenc_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer2_block1_self_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer2_block2_decenc_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer3_block1_self_att has shape:(1, 17, 7, 7)\n",
      "decoder_layer3_block2_decenc_att has shape:(1, 17, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "# Test your function!\n",
    "n_layers = 3\n",
    "emb_d = 13\n",
    "n_heads = 17\n",
    "fully_connected_dim = 8\n",
    "input_vocab_size = 300\n",
    "target_vocab_size = 350\n",
    "max_positional_encoding_input = 12\n",
    "max_positional_encoding_target = 12\n",
    "\n",
    "transformer = Transformer(n_layers, \n",
    "    emb_d, \n",
    "    n_heads, \n",
    "    fully_connected_dim, \n",
    "    input_vocab_size, \n",
    "    target_vocab_size, \n",
    "    max_positional_encoding_input,\n",
    "    max_positional_encoding_target)\n",
    "\n",
    "# 0 is the padding value\n",
    "sentence_a = np.array([[2, 3, 1, 3, 0, 0, 0]])\n",
    "sentence_b = np.array([[1, 3, 4, 0, 0, 0, 0]])\n",
    "\n",
    "enc_padding_mask = create_padding_mask(sentence_a)\n",
    "dec_padding_mask = create_padding_mask(sentence_a)\n",
    "\n",
    "look_ahead_mask = create_look_ahead_mask(sentence_a.shape[1])\n",
    "\n",
    "test_summary, att_weights = transformer(\n",
    "    sentence_a,\n",
    "    sentence_b,\n",
    "    False,\n",
    "    enc_padding_mask,\n",
    "    look_ahead_mask,\n",
    "    dec_padding_mask\n",
    ")\n",
    "\n",
    "print(f\"Using num_layers={n_layers}, target_vocab_size={target_vocab_size} and num_heads={n_heads}:\\n\")\n",
    "print(f\"sentence_a has shape:{sentence_a.shape}\")\n",
    "print(f\"sentence_b has shape:{sentence_b.shape}\")\n",
    "\n",
    "print(f\"\\nOutput of transformer (summary) has shape:{test_summary.shape}\\n\")\n",
    "print(\"Attention weights:\")\n",
    "for name, tensor in att_weights.items():\n",
    "    print(f\"{name} has shape:{tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e342d253",
   "metadata": {},
   "source": [
    "<a name='9'></a>\n",
    "##  Initializing the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "15983097",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "num_layers = 2\n",
    "embedding_dim = 128\n",
    "fully_connected_dim = 128\n",
    "num_heads = 2\n",
    "positional_encoding_length = 256\n",
    "\n",
    "# Initialize the model\n",
    "transformer = Transformer(\n",
    "    num_layers, \n",
    "    embedding_dim, \n",
    "    num_heads, \n",
    "    fully_connected_dim,\n",
    "    vocab_size, \n",
    "    vocab_size, \n",
    "    positional_encoding_length, \n",
    "    positional_encoding_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7f940",
   "metadata": {},
   "source": [
    "<a name='10'></a>\n",
    "## Preparing for Training the Model\n",
    "\n",
    "The original transformer paper uses Adam optimizer with custom learning rate scheduling, which we define in the cell below. This was empirically shown to produce faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a51b569b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, dtype=tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = CustomSchedule(embedding_dim)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed342e02",
   "metadata": {},
   "source": [
    "Below we can plot, how the custom learning rate looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f30b057f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ebcb60",
   "metadata": {},
   "source": [
    "Next, we set up the loss. Since the target sequences are padded, it is important to apply a padding mask when calculating the loss.\n",
    "\n",
    "We will use the sparse categorical cross-entropy loss function (`tf.keras.losses.SparseCategoricalCrossentropy`) and set the parameter `from_logits` to False since the Transformer does not output raw logits since the last layer has a softmax activation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b3a5d905",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "def masked_loss(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "\n",
    "# Here we will store the losses, so you can later plot them\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11bd62",
   "metadata": {},
   "source": [
    "Now we can define our custom training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2fe1570e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, inp, tar):\n",
    "    \"\"\"\n",
    "    One training step for the transformer\n",
    "    Arguments:\n",
    "        inp (tf.Tensor): Input data to summarize\n",
    "        tar (tf.Tensor): Target (summary)\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    # Create masks\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar_inp)[1])\n",
    "    dec_padding_mask = create_padding_mask(inp) # Notice that both encoder and decoder padding masks are equal\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = model(\n",
    "            inp,\n",
    "            tar_inp, \n",
    "            True, \n",
    "            enc_padding_mask, \n",
    "            look_ahead_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = masked_loss(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28afb39",
   "metadata": {},
   "source": [
    "<a name='11'></a>\n",
    "## Summarization\n",
    "\n",
    "The last thing we will implement is inference. With this, we will be able to produce actual summaries of the documents. We will use a simple method called greedy decoding, which means we will predict one word at a time and append it to the output. We will start with an `[SOS]` token and repeat the word by word inference until the model returns us the `[EOS]` token or until we reach the maximum length of the sentence (we need to add this limit, otherwise a poorly trained model could give us infinite sentences without ever producing the `[EOS]` token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d89ba7",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def next_word(model, encoder_input, output):\n",
    "    \"\"\"\n",
    "    Helper function for summarization that uses the model to predict just the next word.\n",
    "    Arguments:\n",
    "        encoder_input (tf.Tensor): Input data to summarize\n",
    "        output (tf.Tensor): (incomplete) target (summary)\n",
    "    Returns:\n",
    "        predicted_id (tf.Tensor): The id of the predicted word\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a padding mask for the input (encoder)\n",
    "    enc_padding_mask = create_padding_mask(encoder_input)\n",
    "    # Create a look-ahead mask for the output\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(output)[1])\n",
    "    # Create a padding mask for the input (decoder)\n",
    "    dec_padding_mask = create_padding_mask(encoder_input)\n",
    "\n",
    "    # Run the prediction of the next word with the transformer model\n",
    "    predictions, attention_weights = model(\n",
    "        encoder_input,\n",
    "        output,\n",
    "        False,\n",
    "        enc_padding_mask,\n",
    "        look_ahead_mask,\n",
    "        dec_padding_mask\n",
    "    )\n",
    "\n",
    "    predictions = predictions[: ,-1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    return predicted_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aca682",
   "metadata": {},
   "source": [
    "Checking if our function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1235a1b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted token: [[14859]]\n",
      "Predicted word: masses\n"
     ]
    }
   ],
   "source": [
    "# Take a random sentence as an input\n",
    "input_document = tokenizer.texts_to_sequences([\"a random sentence\"])\n",
    "input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "encoder_input = tf.expand_dims(input_document[0], 0)\n",
    "\n",
    "# Take the start of sentence token as the only token in the output to predict the next word\n",
    "output = tf.expand_dims([tokenizer.word_index[\"[SOS]\"]], 0)\n",
    "\n",
    "# predict the next word with your function\n",
    "predicted_token = next_word(transformer, encoder_input, output)\n",
    "print(f\"Predicted token: {predicted_token}\")\n",
    "\n",
    "predicted_word = tokenizer.sequences_to_texts(predicted_token.numpy())[0]\n",
    "print(f\"Predicted word: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a5998447",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def summarize(model, input_document):\n",
    "    \"\"\"\n",
    "    A function for summarization using the transformer model\n",
    "    Arguments:\n",
    "        input_document (tf.Tensor): Input data to summarize\n",
    "    Returns:\n",
    "        _ (str): The summary of the input_document\n",
    "    \"\"\"    \n",
    "    input_document = tokenizer.texts_to_sequences([input_document])\n",
    "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', \n",
    "                                                                   truncating='post')\n",
    "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
    "    \n",
    "    output = tf.expand_dims([tokenizer.word_index[\"[SOS]\"]], 0)\n",
    "    \n",
    "    for i in range(decoder_maxlen):\n",
    "        predicted_id = next_word(model, encoder_input, output)\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "        \n",
    "        if predicted_id == tokenizer.word_index[\"[EOS]\"]:\n",
    "            break\n",
    "\n",
    "    return tokenizer.sequences_to_texts(output.numpy())[0]  # since there is just one translated document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af36f0fd",
   "metadata": {},
   "source": [
    "Now we can already summarize a sentence! But beware, since the model was not yet trained at all, it will just produce nonsense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c188899b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set example:\n",
      "[SOS] amanda: i baked  cookies. do you want some?  jerry: sure!  amanda: i'll bring you tomorrow :-) [EOS]\n",
      "\n",
      "Human written summary:\n",
      "[SOS] amanda baked cookies and will bring jerry some tomorrow. [EOS]\n",
      "\n",
      "Model written summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[SOS] masses kindergarten concept kindergarten concept bloomer wilingness sux sam kindergarten lisabeth kindergarten sawyer's sawyer's masses concept bloomer lisabeth bloomer wilingness 80000 bt hotsummer hoax hoax kieslowski wilingness 80000 dont't elis' 🐶❤️👍 cots saaaad evelynn inexperienced suji zubac forthcoming callum farmers extraordinary callum kindergarten worthy extraordinary readable 🐶❤️👍 thinkgn 🐶❤️👍 cots\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_example = 0\n",
    "\n",
    "# Check a summary of a document from the training set\n",
    "print('Training set example:')\n",
    "print(document[training_set_example])\n",
    "print('\\nHuman written summary:')\n",
    "print(summary[training_set_example])\n",
    "print('\\nModel written summary:')\n",
    "summarize(transformer, document[training_set_example])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985425ea",
   "metadata": {},
   "source": [
    "<a name='12'></a>\n",
    "# Training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3f78c347",
   "metadata": {
    "deletable": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 7.886631\n",
      "Time taken for one epoch: 66.99096632003784 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] [EOS]\n",
      "\n",
      "Epoch 2, Loss 6.599631\n",
      "Time taken for one epoch: 32.776081562042236 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] is going to the the the the the the the the the the the the the the the the the the the the the the the new the the the the the the the the the the the the the the the the the the the the the the the\n",
      "\n",
      "Epoch 3, Loss 6.028031\n",
      "Time taken for one epoch: 23.857938528060913 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] tom is going to the new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new\n",
      "\n",
      "Epoch 4, Loss 5.682731\n",
      "Time taken for one epoch: 21.94778823852539 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] tom is going to the new new new new new new new new new new new new new new new job [EOS]\n",
      "\n",
      "Epoch 5, Loss 5.474131\n",
      "Time taken for one epoch: 22.54239273071289 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] the new new new new new new new job and she will be at the weekend [EOS]\n",
      "\n",
      "Epoch 6, Loss 5.321331\n",
      "Time taken for one epoch: 20.394504070281982 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] tom is going to the new job at the party [EOS]\n",
      "\n",
      "Epoch 7, Loss 5.193731\n",
      "Time taken for one epoch: 19.91449999809265 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] tom is going to the party with her [EOS]\n",
      "\n",
      "Epoch 8, Loss 5.082131\n",
      "Time taken for one epoch: 20.52570605278015 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] the new year's eve is going to the party [EOS]\n",
      "\n",
      "Epoch 9, Loss 4.976131\n",
      "Time taken for one epoch: 16.502997875213623 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] the new year's eve is going to the party [EOS]\n",
      "\n",
      "Epoch 10, Loss 4.876131\n",
      "Time taken for one epoch: 18.153587341308594 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] the car is going to the office tomorrow [EOS]\n",
      "\n",
      "Epoch 11, Loss 4.776631\n",
      "Time taken for one epoch: 13.85617733001709 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] the car is going to the cinema with her [EOS]\n",
      "\n",
      "Epoch 12, Loss 4.675731\n",
      "Time taken for one epoch: 9.467329263687134 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] the car is going to the office today [EOS]\n",
      "\n",
      "Epoch 13, Loss 4.573031\n",
      "Time taken for one epoch: 9.568591833114624 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] ben will buy the dog for the office on the office [EOS]\n",
      "\n",
      "Epoch 14, Loss 4.472531\n",
      "Time taken for one epoch: 9.426676988601685 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] alice has sent a photo of the office today [EOS]\n",
      "\n",
      "Epoch 15, Loss 4.370831\n",
      "Time taken for one epoch: 9.134042263031006 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] alice has just arrived to the office today [EOS]\n",
      "\n",
      "Epoch 16, Loss 4.270431\n",
      "Time taken for one epoch: 9.151760339736938 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] alice and alice are going to the cinema with the store he has to go to the cinema [EOS]\n",
      "\n",
      "Epoch 17, Loss 4.167431\n",
      "Time taken for one epoch: 10.165395259857178 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] alice has just arrived to the cinema with amanda and alice [EOS]\n",
      "\n",
      "Epoch 18, Loss 4.072931\n",
      "Time taken for one epoch: 8.98754072189331 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] alice and alice are going to the cinema with alice and hannah [EOS]\n",
      "\n",
      "Epoch 19, Loss 3.970631\n",
      "Time taken for one epoch: 9.128455877304077 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] alice has just finished the door for the wedding he has to go to the cinema with alice [EOS]\n",
      "\n",
      "Epoch 20, Loss 3.879431\n",
      "Time taken for one epoch: 8.618478059768677 sec\n",
      "Example summarization on the test set:\n",
      "  True summarization:\n",
      "    [SOS] hannah needs betty's number but amanda doesn't have it. she needs to contact larry. [EOS]\n",
      "  Predicted summarization:\n",
      "    [SOS] alice has just finished the way to the store with amanda and sara will let hannah know if he doesn't know [EOS]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_example = 0\n",
    "true_summary = summary_test[test_example]\n",
    "true_document = document_test[test_example]\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 20\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    number_of_batches=len(list(enumerate(dataset)))\n",
    "\n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        print(f'Epoch {epoch+1}, Batch {batch+1}/{number_of_batches}', end='\\r')\n",
    "        train_step(transformer, inp, tar)\n",
    "    \n",
    "    print (f'Epoch {epoch+1}, Loss {train_loss.result():.4f}')\n",
    "    losses.append(train_loss.result())\n",
    "    \n",
    "    print (f'Time taken for one epoch: {time.time() - start} sec')\n",
    "    print('Example summarization on the test set:')\n",
    "    print('  True summarization:')\n",
    "    print(f'    {true_summary}')\n",
    "    print('  Predicted summarization:')\n",
    "    print(f'    {summarize(transformer, true_document)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2625084",
   "metadata": {},
   "source": [
    "Plot the loss funtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a5683bb6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a697190",
   "metadata": {},
   "source": [
    "<a name='13'></a>\n",
    "# Summarizing some Sentences!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e91ff849",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set example:\n",
      "[SOS] amanda: i baked  cookies. do you want some?  jerry: sure!  amanda: i'll bring you tomorrow :-) [EOS]\n",
      "\n",
      "Human written summary:\n",
      "[SOS] amanda baked cookies and will bring jerry some tomorrow. [EOS]\n",
      "\n",
      "Model written summary:\n",
      "[SOS] amanda will bring some cookies [EOS]\n"
     ]
    }
   ],
   "source": [
    "training_set_example = 0\n",
    "\n",
    "# Check a summary of a document from the training set\n",
    "print('Training set example:')\n",
    "print(document[training_set_example])\n",
    "print('\\nHuman written summary:')\n",
    "print(summary[training_set_example])\n",
    "print('\\nModel written summary:')\n",
    "print(summarize(transformer, document[training_set_example]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d2ab1199",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set example:\n",
      "[SOS] will: hey babe, what do you want for dinner tonight?  emma:  gah, don't even worry about it tonight  will: what do you mean? everything ok?  emma: not really, but it's ok, don't worry about cooking though, i'm not hungry  will: well what time will you be home?  emma: soon, hopefully  will: you sure? maybe you want me to pick you up?  emma: no no it's alright. i'll be home soon, i'll tell you when i get home.   will: alright, love you.   emma: love you too.  [EOS]\n",
      "\n",
      "Human written summary:\n",
      "[SOS] emma will be home soon and she will let will know. [EOS]\n",
      "\n",
      "Model written summary:\n",
      "[SOS] emma will pick up with emma at home tonight [EOS]\n"
     ]
    }
   ],
   "source": [
    "test_set_example = 3\n",
    "\n",
    "# Check a summary of a document from the test set\n",
    "print('Test set example:')\n",
    "print(document_test[test_set_example])\n",
    "print('\\nHuman written summary:')\n",
    "print(summary_test[test_set_example])\n",
    "print('\\nModel written summary:')\n",
    "print(summarize(transformer, document_test[test_set_example]))"
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
